{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c794fda6-391e-4509-9ec9-98712055ebaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "\n",
    "def search_videos(query: str, size: int = 5) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Search for videos whose titles or subtitles match a given query.\n",
    "    \n",
    "    Returns highlighted match information including video IDs and snippets.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query string to match against video titles and subtitles. Must be a non-empty string.\n",
    "        size (int, optional): Maximum number of results to return. Must be a positive integer. Defaults to 5.\n",
    "    \"\"\"\n",
    "    body = {\n",
    "        \"size\": size,\n",
    "        \"query\": {\n",
    "            \"multi_match\": {\n",
    "                \"query\": query,\n",
    "                \"fields\": [\"title^3\", \"subtitles\"],\n",
    "                \"type\": \"best_fields\",\n",
    "                \"analyzer\": \"english_with_stop_and_stem\"\n",
    "            }\n",
    "        },\n",
    "        \"highlight\": {\n",
    "            \"pre_tags\": [\"*\"],\n",
    "            \"post_tags\": [\"*\"],\n",
    "            \"fields\": {\n",
    "                \"title\": {\n",
    "                    \"fragment_size\": 150,\n",
    "                    \"number_of_fragments\": 1\n",
    "                },\n",
    "                \"subtitles\": {\n",
    "                    \"fragment_size\": 150,\n",
    "                    \"number_of_fragments\": 1\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    response = es.search(index=\"podcasts\", body=body)\n",
    "    hits = response.body['hits']['hits']\n",
    "    \n",
    "    results = []\n",
    "    for hit in hits:\n",
    "        highlight = hit['highlight']\n",
    "        highlight['video_id'] = hit['_id']\n",
    "        results.append(highlight)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def get_subtitles_by_id(video_id: str) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieve the full subtitle content for a specific video.\n",
    "\n",
    "    Args:\n",
    "        video_id (str): the YouTube video id for which we want to get the subtitles\n",
    "    \"\"\"\n",
    "    result = es.get(index=\"podcasts\", id=video_id)\n",
    "    return result['_source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de7fcfc5-3a52-4ba6-a8c5-381db15c283a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'subtitles': ['and we have a special guest\\n1:34 today BOS BOS is an *AI* and data engineer\\n1:38 he specializes in moving *AI* projects\\n1:40 from the good enough for demo'],\n",
       "  'title': ['Data Intensive *AI*'],\n",
       "  'video_id': 'BP6w_vKySN0'},\n",
       " {'subtitles': ['first but you still\\n42:37 want to want to leverage *Ai* and you want\\n42:39 to you know in introduce *AI* into\\n42:43 services that your bank offers um of\\n42'],\n",
       "  'title': ['Trends in *AI* Infrastructure'],\n",
       "  'video_id': '1aMuynlLM3o'},\n",
       " {'subtitles': [\"0:00 this week we'll talk about *AI* for\\n0:03 digital Healthcare and we have a special\\n0:05 guest today Maria and by the way should\\n0:07 I say Maria Lisa\"],\n",
       "  'title': ['*AI* for Digital Health'],\n",
       "  'video_id': 'whpkDmVVGUE'},\n",
       " {'subtitles': [\"okay this\\n1:15 week we'll talk about bringing together\\n1:16 research and Industry and how\\n1:18 explainable and interpretable machine\\n1:20 learning and *AI*\"],\n",
       "  'title': ['Interpretable *AI* and ML'],\n",
       "  'video_id': 'EQcY83VA0Us'},\n",
       " {'title': ['Staff *AI* Engineer'], 'video_id': '_xr1_xb736E'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_videos('how do I get rich with AI?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac2229c-e06f-4cdf-ba72-d7547f1eeedb",
   "metadata": {},
   "source": [
    "## Simple reasearch agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1741610-c50a-4d90-be94-5c6064cbbd09",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      4\u001b[39m api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m research_instructions = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33mYou\u001b[39m\u001b[33m'\u001b[39m\u001b[33mre a helpful researcher agent.\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[33m\"\"\"\u001b[39m.strip()\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m research_agent = \u001b[43mAgent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mresearch_agent\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresearch_instructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mopenai:gpt-4o-mini\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43msearch_videos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_subtitles_by_id\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m research_agent.run(\n\u001b[32m     18\u001b[39m     user_prompt=\u001b[33m'\u001b[39m\u001b[33mhow do I get rich with AI?\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     19\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(result.output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub_HT/project_deep_research_agent/src/flow/.venv/lib/python3.13/site-packages/pydantic_ai/agent/__init__.py:308\u001b[39m, in \u001b[36mAgent.__init__\u001b[39m\u001b[34m(self, model, output_type, instructions, system_prompt, deps_type, name, model_settings, retries, validation_context, output_retries, tools, builtin_tools, prepare_tools, prepare_output_tools, toolsets, defer_model_check, end_strategy, instrument, history_processors, event_stream_handler, tool_timeout, **_deprecated_kwargs)\u001b[39m\n\u001b[32m    306\u001b[39m     \u001b[38;5;28mself\u001b[39m._model = model\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m     \u001b[38;5;28mself\u001b[39m._model = \u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43minfer_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[38;5;28mself\u001b[39m._name = name\n\u001b[32m    311\u001b[39m \u001b[38;5;28mself\u001b[39m.end_strategy = end_strategy\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub_HT/project_deep_research_agent/src/flow/.venv/lib/python3.13/site-packages/pydantic_ai/models/__init__.py:1075\u001b[39m, in \u001b[36minfer_model\u001b[39m\u001b[34m(model, provider_factory)\u001b[39m\n\u001b[32m   1069\u001b[39m     warnings.warn(\n\u001b[32m   1070\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[33m'\u001b[39m\u001b[33mvertexai\u001b[39m\u001b[33m'\u001b[39m\u001b[33m provider name is deprecated. Use \u001b[39m\u001b[33m'\u001b[39m\u001b[33mgoogle-vertex\u001b[39m\u001b[33m'\u001b[39m\u001b[33m instead.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1071\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m   1072\u001b[39m     )\n\u001b[32m   1073\u001b[39m     provider_name = \u001b[33m'\u001b[39m\u001b[33mgoogle-vertex\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1075\u001b[39m provider: Provider[Any] = \u001b[43mprovider_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprovider_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1077\u001b[39m model_kind = provider_name\n\u001b[32m   1078\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_kind.startswith(\u001b[33m'\u001b[39m\u001b[33mgateway/\u001b[39m\u001b[33m'\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub_HT/project_deep_research_agent/src/flow/.venv/lib/python3.13/site-packages/pydantic_ai/providers/__init__.py:169\u001b[39m, in \u001b[36minfer_provider\u001b[39m\u001b[34m(provider)\u001b[39m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    168\u001b[39m     provider_class = infer_provider_class(provider)\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprovider_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub_HT/project_deep_research_agent/src/flow/.venv/lib/python3.13/site-packages/pydantic_ai/providers/openai.py:85\u001b[39m, in \u001b[36mOpenAIProvider.__init__\u001b[39m\u001b[34m(self, base_url, api_key, openai_client, http_client)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     84\u001b[39m     http_client = cached_async_http_client(provider=\u001b[33m'\u001b[39m\u001b[33mopenai\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[38;5;28mself\u001b[39m._client = \u001b[43mAsyncOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_client\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp_client\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub_HT/project_deep_research_agent/src/flow/.venv/lib/python3.13/site-packages/openai/_client.py:488\u001b[39m, in \u001b[36mAsyncOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    486\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    489\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    490\u001b[39m     )\n\u001b[32m    491\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(api_key):\n\u001b[32m    492\u001b[39m     \u001b[38;5;28mself\u001b[39m.api_key = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from pydantic_ai import Agent\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "research_instructions = \"\"\"\n",
    "You're a helpful researcher agent.\n",
    "\"\"\".strip()\n",
    "\n",
    "research_agent = Agent(\n",
    "    name='research_agent',\n",
    "    instructions=research_instructions,\n",
    "    model='openai:gpt-4o-mini',\n",
    "    tools=[search_videos, get_subtitles_by_id]\n",
    ")\n",
    "\n",
    "result = await research_agent.run(\n",
    "    user_prompt='how do I get rich with AI?'\n",
    ")\n",
    "\n",
    "print(result.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4938cd-14ea-4ba3-b3cc-073d2f792954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1b382e-a339-40c2-9bfb-9c8ef219567c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7136322-7c8d-4225-b0b7-5cd6a01edb77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4028c761-6afa-486b-8c3a-a25aeaf5f0aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c817b53-3835-4440-83ff-2cf248b93ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3ae02c-566a-4edc-bcaa-47b616d227e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc490f61-9377-47f8-82af-0cd5eb517945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee8eae7-508c-40f8-b602-65feae1adb2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
